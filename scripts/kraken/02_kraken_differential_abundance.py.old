#!/usr/bin/env python3
"""
Analyze RSV nasal microbiome data from Kraken2/Bracken across timing points based on severity and symptoms.

This script:
1. Loads processed Kraken2/Bracken abundance data
2. Performs differential abundance testing:
   - Between timing points (Prior, Acute, Post)
   - Between severity groups at each time point
   - Between symptom groups at each time point
3. Generates faceted boxplots for differentially abundant species
4. Uses kraken_tools for enhanced analysis capabilities

Usage:
    python scripts/kraken/02_kraken_differential_abundance.py [--abundance-file ABUNDANCE_FILE] [--output-dir OUTPUT_DIR]
"""

import os
import sys
import glob
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import re
from scipy.stats import mannwhitneyu, kruskal
from statsmodels.stats.multitest import multipletests
import traceback

# Add project root to Python path
project_root = Path(__file__).resolve().parents[2]
sys.path.append(str(project_root))

# Add kraken_tools to Python path
kraken_tools_dir = Path.home() / "Documents" / "Code" / "kraken_tools"
sys.path.append(str(kraken_tools_dir))

# Import functions from kraken_tools
try:
    from kraken_tools.analysis.differential import run_differential_abundance_analysis
    from kraken_tools.analysis.metadata import read_and_process_metadata
    from kraken_tools.analysis.normalization_and_filtering import filter_low_abundance_taxa
    kraken_tools_available = True
except ImportError:
    kraken_tools_available = False
    print("Warning: kraken_tools module not available. Using built-in functions.")

# Set plotting style
plt.style.use('seaborn-v0_8-whitegrid')
sns.set(font_scale=1.1)

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description='Analyze RSV microbiome data from Kraken2/Bracken')
    parser.add_argument('--abundance-file', type=str, 
                        default='results/kraken_analysis/filtered_kraken_s_abundance.tsv',
                        help='Path to processed Kraken abundance file')
    parser.add_argument('--output-dir', type=str, default='results/kraken_differential',
                       help='Directory to save analysis results')
    parser.add_argument('--metadata', type=str, default='metadata.csv',
                       help='Path to metadata file')
    parser.add_argument('--sample-id-column', type=str, default='SampleID',
                       help='Column name for sample IDs in metadata')
    parser.add_argument('--taxonomic-level', type=str, default='S',
                       choices=['D', 'P', 'C', 'O', 'F', 'G', 'S'],
                       help='Taxonomic level for analysis')
    parser.add_argument('--group-by', type=str, default='Severity,Symptoms,Timing',
                       help='Comma-separated list of grouping variables for differential testing')
    parser.add_argument('--min-prevalence', type=float, default=0.1,
                       help='Minimum prevalence to keep taxon')
    parser.add_argument('--min-abundance', type=float, default=0.01,
                       help='Minimum relative abundance to keep taxon')
    parser.add_argument('--methods', type=str, default='aldex2,ancom,ancom-bc',
                       help='Comma-separated list of differential abundance methods to use')
    parser.add_argument('--p-value-threshold', type=float, default=0.05,
                       help='P-value threshold for significance')
    parser.add_argument('--top-taxa', type=int, default=10,
                       help='Number of top differential taxa to visualize')
    parser.add_argument('--stratify-by-timing', action='store_true',
                       help='Stratify analyses by timing point (Prior, Acute, Post)')
    return parser.parse_args()

# We need a function to process Kraken taxonomic names
def parse_kraken_taxonomy(taxon_name):
    """
    Parse Kraken/Bracken taxonomic name into components.
    
    Parameters:
    -----------
    taxon_name : str
        Taxonomic name from Kraken/Bracken
        
    Returns:
    --------
    dict
        Dictionary with taxonomic information
    """
    # Check if we have a standard format
    if not taxon_name or not isinstance(taxon_name, str):
        return {'name': str(taxon_name), 'genus': 'Unknown', 'species': 'Unknown'}
    
    # Bracken usually outputs names like 'Escherichia coli' or 'Homo sapiens'
    # or with full taxonomic path like 'd__Bacteria|p__Proteobacteria|...|s__Escherichia coli'
    
    # For full path format
    if '|' in taxon_name:
        components = taxon_name.split('|')
        # Get the last component which should be species
        species_part = components[-1]
        if species_part.startswith('s__'):
            species = species_part[3:]  # Remove the s__ prefix
        else:
            species = species_part
            
        # Try to get genus
        genus = "Unknown"
        for comp in components:
            if comp.startswith('g__'):
                genus = comp[3:]  # Remove the g__ prefix
                break
        
        # Return parsed information
        return {
            'name': taxon_name,
            'genus': genus,
            'species': species if species != '' else 'Unknown'
        }
    
    # For standard binomial format
    parts = taxon_name.split()
    if len(parts) >= 2:
        genus = parts[0]
        species = ' '.join(parts[1:])
        return {'name': taxon_name, 'genus': genus, 'species': species}
    
    # For genus-only or other formats
    return {'name': taxon_name, 'genus': taxon_name, 'species': 'Unknown'}


def load_abundance_data(file_path):
    """
    Load Kraken/Bracken abundance data from file.
    
    Parameters:
    -----------
    file_path : str
        Path to abundance file (can be TSV or CSV)
        
    Returns:
    --------
    pandas.DataFrame
        Abundance DataFrame with taxa as index, samples as columns
    """
    try:
        # Determine file format based on extension
        if file_path.lower().endswith('.csv'):
            df = pd.read_csv(file_path, index_col=0)
        else:
            # Default to tab-separated
            df = pd.read_csv(file_path, sep='\t', index_col=0)
        
        # Quick validation
        if df.shape[0] == 0 or df.shape[1] == 0:
            raise ValueError(f"Abundance file has {df.shape[0]} rows and {df.shape[1]} columns")
        
        # Fill NAs with zeros
        df = df.fillna(0)
        
        return df
        
    except Exception as e:
        print(f"Error loading abundance file: {str(e)}")
        traceback.print_exc()
        sys.exit(1)
        
        
def run_differential_analysis(abundance_df, metadata_df, group_var, output_dir, methods=None, min_abundance=0.01, min_prevalence=0.1, p_value_threshold=0.05):
    """
    Run differential abundance analysis using kraken_tools if available, or built-in functions.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Abundance DataFrame with taxa as index, samples as columns
    metadata_df : pandas.DataFrame
        Metadata DataFrame with samples as index
    group_var : str
        Metadata variable for grouping
    output_dir : str
        Directory to save results
    methods : list
        List of methods to use (aldex2, ancom, ancom-bc)
    min_abundance : float
        Minimum mean abundance threshold
    min_prevalence : float
        Minimum prevalence threshold  
    p_value_threshold : float
        Threshold for significance
        
    Returns:
    --------
    dict
        Results from the differential abundance analysis
    """
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # If kraken_tools available, use it
    if kraken_tools_available:
        try:
            print(f"Running differential abundance analysis with kraken_tools for {group_var}")
            
            # Filter abundance data if needed
            if min_abundance > 0 or min_prevalence > 0:
                filtered_df = filter_low_abundance_taxa(
                    abundance_df, 
                    min_abundance=min_abundance, 
                    min_prevalence=min_prevalence
                )
            else:
                filtered_df = abundance_df.copy()
                
            # Run differential abundance analysis
            results = run_differential_abundance_analysis(
                filtered_df,
                metadata_df,
                output_dir,
                group_col=group_var,
                methods=methods
            )
            
            return results
            
        except Exception as e:
            print(f"Error using kraken_tools for differential analysis: {str(e)}")
            print("Falling back to built-in methods")
    
    # Fall back to built-in methods
    print(f"Running built-in differential abundance analysis for {group_var}")
    
    # Get values for grouping
    if group_var not in metadata_df.columns:
        print(f"Error: Group variable '{group_var}' not found in metadata")
        return None
        
    # Find common samples
    common_samples = list(set(abundance_df.columns).intersection(set(metadata_df.index)))
    if len(common_samples) < 5:
        print(f"Error: Too few samples ({len(common_samples)}) for differential analysis")
        return None
        
    # Filter to common samples
    filtered_abundance = abundance_df[common_samples]
    
    # Get group information
    groups = metadata_df.loc[common_samples, group_var]
    unique_groups = groups.unique()
    
    # Filter by abundance and prevalence
    if min_abundance > 0 or min_prevalence > 0:
        # Calculate mean abundance per taxon
        mean_abundance = filtered_abundance.mean(axis=1)
        
        # Calculate prevalence (proportion of samples where taxon is present)
        prevalence = (filtered_abundance > 0).mean(axis=1)
        
        # Apply filters
        before_count = filtered_abundance.shape[0]
        filtered_abundance = filtered_abundance.loc[
            (mean_abundance >= min_abundance) & (prevalence >= min_prevalence)
        ]
        after_count = filtered_abundance.shape[0]
        
        print(f"Filtered from {before_count} to {after_count} taxa based on abundance/prevalence thresholds")
    
    # Decide which test to use based on number of groups
    if len(unique_groups) == 2:
        print(f"Running Mann-Whitney U test for {group_var}")
        results = run_mann_whitney_test(filtered_abundance, groups, unique_groups, p_value_threshold)
    else:
        print(f"Running Kruskal-Wallis test for {group_var} with {len(unique_groups)} groups")
        results = run_kruskal_wallis_test(filtered_abundance, groups, unique_groups, p_value_threshold)
    
    # Save results
    results_file = os.path.join(output_dir, f"diff_abundance_{group_var}.tsv")
    results.to_csv(results_file, sep='\t')
    print(f"Saved differential abundance results to {results_file}")
    
    return results


def run_mann_whitney_test(abundance_df, groups, unique_groups, p_value_threshold=0.05):
    """
    Run Mann-Whitney U test for differential abundance between two groups.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Abundance DataFrame with taxa as index, samples as columns
    groups : pandas.Series
        Group assignment for each sample
    unique_groups : array-like
        Unique group values
    p_value_threshold : float
        Threshold for significance
        
    Returns:
    --------
    pandas.DataFrame
        Results of differential abundance testing
    """
    results = []
    
    # Get sample IDs for each group
    group1_samples = groups[groups == unique_groups[0]].index
    group2_samples = groups[groups == unique_groups[1]].index
    
    # Count number of samples in each group
    n_group1 = len(group1_samples)
    n_group2 = len(group2_samples)
    
    if n_group1 < 3 or n_group2 < 3:
        print(f"Warning: Small sample sizes (group1: {n_group1}, group2: {n_group2})")
    
    # Loop through each taxon
    for taxon in abundance_df.index:
        # Get abundance values for each group
        values1 = abundance_df.loc[taxon, group1_samples]
        values2 = abundance_df.loc[taxon, group2_samples]
        
        # Calculate mean abundance in each group
        mean1 = values1.mean()
        mean2 = values2.mean()
        
        # Calculate fold change (log2)
        # Add small pseudocount to avoid division by zero
        pseudocount = 1e-5
        fold_change = np.log2((mean2 + pseudocount) / (mean1 + pseudocount))
        
        # Perform Mann-Whitney U test
        try:
            stat, p_value = mannwhitneyu(values1, values2, alternative='two-sided')
        except Exception as e:
            # If test fails, set p-value to 1
            p_value = 1.0
        
        # Parse taxonomy (for easier interpretation)
        tax_info = parse_kraken_taxonomy(taxon)
        
        results.append({
            'Taxon': taxon,
            'Genus': tax_info['genus'],
            'Species': tax_info['species'],
            'P-value': p_value,
            'Group1': unique_groups[0],
            'Group2': unique_groups[1],
            'Mean in Group1': mean1,
            'Mean in Group2': mean2,
            'Log2 Fold Change': fold_change,
            'Test': 'Mann-Whitney U'
        })
    
    # Create DataFrame from results
    results_df = pd.DataFrame(results)
    
    # Apply multiple testing correction
    if not results_df.empty and len(results_df) > 1:
        try:
            # Use Benjamini-Hochberg procedure for FDR control
            results_df['Adjusted P-value'] = multipletests(
                results_df['P-value'], method='fdr_bh'
            )[1]
        except Exception as e:
            print(f"Error applying multiple testing correction: {str(e)}")
            results_df['Adjusted P-value'] = results_df['P-value']
    else:
        results_df['Adjusted P-value'] = results_df['P-value']
    
    # Mark significant taxa
    results_df['Significant'] = results_df['Adjusted P-value'] < p_value_threshold
    
    # Sort by adjusted p-value
    results_df = results_df.sort_values('Adjusted P-value')
    
    return results_df


def run_kruskal_wallis_test(abundance_df, groups, unique_groups, p_value_threshold=0.05):
    """
    Run Kruskal-Wallis test for differential abundance between multiple groups.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Abundance DataFrame with taxa as index, samples as columns
    groups : pandas.Series
        Group assignment for each sample
    unique_groups : array-like
        Unique group values
    p_value_threshold : float
        Threshold for significance
        
    Returns:
    --------
    pandas.DataFrame
        Results of differential abundance testing
    """
    results = []
    
    # Loop through each taxon
    for taxon in abundance_df.index:
        # Initialize group values and means
        group_values = {}
        group_means = {}
        
        # Get values and calculate means
        for group in unique_groups:
            group_samples = groups[groups == group].index
            group_values[group] = abundance_df.loc[taxon, group_samples]
            group_means[group] = group_values[group].mean()
        
        # Perform Kruskal-Wallis test
        try:
            # Prepare data for the test
            all_values = [group_values[group] for group in unique_groups]
            stat, p_value = kruskal(*all_values)
        except Exception as e:
            # If test fails, set p-value to 1
            p_value = 1.0
        
        # Calculate maximum fold change between any two groups
        max_fold_change = 0
        max_group_pair = None
        
        for i, group1 in enumerate(unique_groups):
            for group2 in unique_groups[i+1:]:
                # Add small pseudocount to avoid division by zero
                pseudocount = 1e-5
                fold_change = np.abs(np.log2((group_means[group2] + pseudocount) / (group_means[group1] + pseudocount)))
                
                if fold_change > max_fold_change:
                    max_fold_change = fold_change
                    max_group_pair = (group1, group2)
        
        # Parse taxonomy (for easier interpretation)
        tax_info = parse_kraken_taxonomy(taxon)
        
        # Create result entry
        result = {
            'Taxon': taxon,
            'Genus': tax_info['genus'],
            'Species': tax_info['species'],
            'P-value': p_value,
            'Test': 'Kruskal-Wallis'
        }
        
        # Add mean for each group
        for group in unique_groups:
            result[f'Mean in {group}'] = group_means[group]
        
        # Add fold change information
        if max_group_pair:
            result['Max Log2 Fold Change'] = max_fold_change
            result['Max Fold Change Groups'] = f'{max_group_pair[0]} vs {max_group_pair[1]}'
        
        results.append(result)
    
    # Create DataFrame from results
    results_df = pd.DataFrame(results)
    
    # Apply multiple testing correction
    if not results_df.empty and len(results_df) > 1:
        try:
            # Use Benjamini-Hochberg procedure for FDR control
            results_df['Adjusted P-value'] = multipletests(
                results_df['P-value'], method='fdr_bh'
            )[1]
        except Exception as e:
            print(f"Error applying multiple testing correction: {str(e)}")
            results_df['Adjusted P-value'] = results_df['P-value']
    else:
        results_df['Adjusted P-value'] = results_df['P-value']
    
    # Mark significant taxa
    results_df['Significant'] = results_df['Adjusted P-value'] < p_value_threshold
    
    # Sort by adjusted p-value
    results_df = results_df.sort_values('Adjusted P-value')
    
    return results_df


def plot_taxa_boxplots(abundance_df, metadata_df, group_var, results_df, output_dir, top_n=5):
    """
    Create boxplots for top differentially abundant taxa.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Abundance DataFrame with taxa as index, samples as columns
    metadata_df : pandas.DataFrame
        Metadata DataFrame with samples as index
    group_var : str
        Metadata variable for grouping
    results_df : pandas.DataFrame
        Differential abundance results 
    output_dir : str
        Directory to save plots
    top_n : int
        Number of top taxa to visualize
        
    Returns:
    --------
    list
        Paths to created plot files
    """
    # Create output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Get significant taxa
    sig_taxa = results_df[results_df['Significant'] == True]
    
    if sig_taxa.empty:
        print(f"No significant taxa found for {group_var}")
        return []
    
    # Get top taxa by adjusted p-value
    top_taxa = sig_taxa.head(top_n)['Taxon'].tolist()
    
    # Get common samples
    common_samples = list(set(abundance_df.columns).intersection(set(metadata_df.index)))
    
    # Filter to common samples
    filtered_abundance = abundance_df[common_samples]
    
    # Create a boxplot for each taxon
    plot_files = []
    
    for taxon in top_taxa:
        try:
            # Get taxonomic info for better plot titles
            tax_info = parse_kraken_taxonomy(taxon)
            
            # Create figure
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # Prepare data for plotting
            plot_data = pd.DataFrame({
                'Abundance': filtered_abundance.loc[taxon],
                group_var: metadata_df.loc[filtered_abundance.columns, group_var]
            })
            
            # Create boxplot
            sns.boxplot(x=group_var, y='Abundance', data=plot_data, ax=ax)
            
            # Add individual points
            sns.stripplot(x=group_var, y='Abundance', data=plot_data, 
                         color='black', size=4, alpha=0.5, ax=ax)
            
            # Get p-value info
            p_value = results_df[results_df['Taxon'] == taxon]['Adjusted P-value'].values[0]
            
            # Set titles and labels
            if tax_info['species'] != 'Unknown':
                title = f"{tax_info['genus']} {tax_info['species']}"
            else:
                title = taxon
                
            ax.set_title(f"{title}\n(adj. p-value: {p_value:.2e})")
            ax.set_xlabel(group_var)
            ax.set_ylabel('Relative Abundance')
            
            # Save figure
            safe_taxon = taxon.replace(' ', '_').replace('/', '_').replace(':', '_').replace('|', '_')
            plot_file = os.path.join(output_dir, f"{safe_taxon}_{group_var}.pdf")
            plt.tight_layout()
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            plt.close(fig)
            
            plot_files.append(plot_file)
            
        except Exception as e:
            print(f"Error creating boxplot for {taxon}: {str(e)}")
    
    return plot_files


def main():
    """Main function to run differential abundance analysis."""
    # Parse arguments
    args = parse_args()
    
    # Create output directories
    output_dir = Path(args.output_dir)
    os.makedirs(output_dir, exist_ok=True)
    figures_dir = output_dir / 'figures'
    tables_dir = output_dir / 'tables'
    boxplots_dir = figures_dir / 'boxplots'
    
    for dir_path in [output_dir, figures_dir, tables_dir, boxplots_dir]:
        os.makedirs(dir_path, exist_ok=True)
    
    # Load abundance data
    print(f"Loading abundance data from {args.abundance_file}")
    abundance_df = load_abundance_data(args.abundance_file)
    print(f"Loaded data with {abundance_df.shape[0]} taxa and {abundance_df.shape[1]} samples")
    
    # Load metadata
    print(f"Loading metadata from {args.metadata}")
    if kraken_tools_available:
        metadata_df = read_and_process_metadata(args.metadata)
    else:
        metadata_df = pd.read_csv(args.metadata)
        metadata_df.set_index(args.sample_id_column, inplace=True)
    
    print(f"Loaded metadata with {metadata_df.shape[0]} samples and {metadata_df.shape[1]} columns")
    
    # Get analysis variables
    group_vars = args.group_by.split(',')
    methods = args.methods.split(',')
    
    # Check for timing variable if stratification is requested
    if args.stratify_by_timing:
        if 'Timing' not in metadata_df.columns:
            print("Warning: 'Timing' column not found in metadata. Cannot stratify by timing.")
            args.stratify_by_timing = False
    
    # Run differential abundance analysis for each grouping variable
    for group_var in group_vars:
        if group_var not in metadata_df.columns:
            print(f"Warning: {group_var} not found in metadata. Skipping.")
            continue
            
        print(f"\nAnalyzing differential abundance by {group_var}")
        
        # If stratifying by timing, analyze each timing point separately
        if args.stratify_by_timing and group_var != 'Timing':
            timing_values = metadata_df['Timing'].unique()
            
            for timing in timing_values:
                print(f"\n  Analyzing {group_var} within timing: {timing}")
                
                # Filter metadata to this timing
                timing_metadata = metadata_df[metadata_df['Timing'] == timing]
                
                # Skip if too few samples
                if timing_metadata.shape[0] < 5:
                    print(f"  Too few samples ({timing_metadata.shape[0]}) for timing {timing}. Skipping.")
                    continue
                
                # Create output subdirectory
                timing_dir = output_dir / f"timing_{timing}"
                os.makedirs(timing_dir, exist_ok=True)
                
                # Run differential analysis
                results = run_differential_analysis(
                    abundance_df, 
                    timing_metadata, 
                    group_var, 
                    timing_dir,
                    methods=methods,
                    min_abundance=args.min_abundance,
                    min_prevalence=args.min_prevalence,
                    p_value_threshold=args.p_value_threshold
                )
                
                if results is not None:
                    # Create boxplots
                    boxplots_path = timing_dir / 'boxplots'
                    plot_files = plot_taxa_boxplots(
                        abundance_df,
                        timing_metadata,
                        group_var,
                        results,
                        boxplots_path,
                        top_n=args.top_taxa
                    )
                    
                    # Report significant taxa
                    sig_count = sum(results['Significant'] == True)
                    print(f"  Found {sig_count} significantly different taxa for {group_var} in {timing}")
                
        else:
            # Create output subdirectory
            group_dir = output_dir / f"group_{group_var}"
            os.makedirs(group_dir, exist_ok=True)
            
            # Run differential analysis
            results = run_differential_analysis(
                abundance_df, 
                metadata_df, 
                group_var, 
                group_dir,
                methods=methods,
                min_abundance=args.min_abundance,
                min_prevalence=args.min_prevalence,
                p_value_threshold=args.p_value_threshold
            )
            
            if results is not None:
                # Create boxplots
                boxplots_path = group_dir / 'boxplots'
                plot_files = plot_taxa_boxplots(
                    abundance_df,
                    metadata_df,
                    group_var,
                    results,
                    boxplots_path,
                    top_n=args.top_taxa
                )
                
                # Report significant taxa
                sig_count = sum(results['Significant'] == True)
                print(f"  Found {sig_count} significantly different taxa for {group_var}")
    
    print("\nDifferential abundance analysis complete!")


if __name__ == "__main__":
    main()
    organism_part = parts[1]
    
    # Look for typical binomial nomenclature pattern
    species_match = re.search(r'([A-Z][a-z]+)\s+([a-z]+)', organism_part)
    if species_match:
        taxonomy['genus'] = species_match.group(1)
        taxonomy['species'] = species_match.group(2)
        taxonomy['full_name'] = f"{taxonomy['genus']} {taxonomy['species']}"
        
        # Try to extract strain if present
        strain_match = re.search(r'strain\s+([^\s,]+)', organism_part)
        if strain_match:
            taxonomy['strain'] = strain_match.group(1)
    else:
        # Fall back to using the full text
        taxonomy['full_name'] = organism_part.split(',')[0].strip()
    
    return taxonomy

def parse_sylph_file(file_path, abundance_type='Taxonomic_abundance', min_ani=95.0, min_coverage=0.05):
    """
    Parse a Sylph output file and extract abundance data.
    
    Parameters:
    -----------
    file_path : str
        Path to the Sylph output file
    abundance_type : str
        Which abundance column to use ('Taxonomic_abundance' or 'Sequence_abundance')
    min_ani : float
        Minimum Adjusted ANI to include
    min_coverage : float
        Minimum effective coverage to include
        
    Returns:
    --------
    pandas.DataFrame
        DataFrame with species as index and abundance as values
    """
    # Check if file exists
    if not os.path.exists(file_path):
        print(f"Warning: File not found: {file_path}")
        return pd.DataFrame()
    
    try:
        # Read the Sylph file
        # The file doesn't have a clean header - need to handle specially
        with open(file_path, 'r') as f:
            header_line = f.readline().strip()
        
        # Clean up header line and split into column names
        header_columns = re.split(r'\s+', header_line.strip())
        
        # Read the file with the cleaned column names
        try:
            df = pd.read_csv(file_path, sep='\t', skiprows=1, names=header_columns)
            
            # Check if required columns exist
            required_cols = ['Adjusted_ANI', 'Eff_cov', 'Contig_name', abundance_type]
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                print(f"  Warning: Missing required columns: {missing_cols}")
                print(f"  Available columns: {df.columns.tolist()}")
                return pd.DataFrame()
            
        except Exception as e:
            print(f"  Error reading CSV: {str(e)}")
            return pd.DataFrame()
        
        # Filter based on ANI and coverage
        df = df[df['Adjusted_ANI'] >= min_ani]
        df = df[df['Eff_cov'] >= min_coverage]
        
        # Extract taxonomic information
        taxonomic_info = df['Contig_name'].apply(extract_taxonomic_info)
        tax_df = pd.DataFrame.from_records(taxonomic_info.tolist())
        
        # Join with the original dataframe
        df = pd.concat([df, tax_df], axis=1)
        
        # Use full species names for more accurate identification
        # Aggregate by species name and sum abundances
        abundance_data = {}
        
        # For each unique species, sum the abundance
        for species_name, group in df.groupby('full_name'):
            if species_name and not pd.isna(species_name):
                abundance_data[species_name] = group[abundance_type].sum()
        
        # Convert to DataFrame
        abundance_df = pd.DataFrame(list(abundance_data.items()), columns=['Taxon', 'abundance'])
        abundance_df.set_index('Taxon', inplace=True)
        
        return abundance_df
    
    except Exception as e:
        print(f"Error parsing {file_path}: {str(e)}")
        return pd.DataFrame()

def combine_sylph_samples(files, sample_ids=None, abundance_type='Taxonomic_abundance', 
                          min_ani=95.0, min_coverage=0.05):
    """
    Combine multiple Sylph output files into a single abundance table.
    
    Parameters:
    -----------
    files : list
        List of file paths to Sylph output files
    sample_ids : list, optional
        List of sample IDs corresponding to each file
    abundance_type : str
        Which abundance column to use
    min_ani : float
        Minimum Adjusted ANI to include
    min_coverage : float
        Minimum effective coverage to include
        
    Returns:
    --------
    pandas.DataFrame
        Combined abundance table with species as rows and samples as columns
    """
    dfs = []
    successful_files = []
    successful_sample_ids = []
    
    if sample_ids is None:
        # Extract sample IDs from file names
        sample_ids = []
        for f in files:
            # Extract sample ID from the Sylph output file name pattern
            match = re.search(r'(\d+-DNA|\w+)_profiled_', os.path.basename(f))
            if match:
                sample_ids.append(match.group(1))
            else:
                # Fallback to file basename without extension
                sample_ids.append(os.path.splitext(os.path.basename(f))[0])
    
    if len(files) != len(sample_ids):
        raise ValueError("Number of files must match number of sample IDs")
    
    for i, file_path in enumerate(files):
        try:
            # Parse the Sylph file
            print(f"Processing file {i+1}/{len(files)}: {os.path.basename(file_path)}")
            df = parse_sylph_file(file_path, abundance_type, min_ani, min_coverage)
            
            if df.empty:
                print(f"Warning: No data extracted from {file_path}")
                continue
                
            # Set column name to sample ID
            df.columns = [sample_ids[i]]
            
            # Check for duplicate indices and handle them
            if df.index.duplicated().any():
                print(f"Warning: Found duplicate taxa in {sample_ids[i]}, keeping first occurrence")
                df = df[~df.index.duplicated(keep='first')]
            
            dfs.append(df)
            successful_files.append(file_path)
            successful_sample_ids.append(sample_ids[i])
            print(f"Successfully processed {os.path.basename(file_path)}")
        except Exception as e:
            print(f"Error processing {file_path}: {str(e)}")
            continue
    
    if not dfs:
        # Return an empty DataFrame with a warning
        print("\nWarning: No valid data frames to combine. Returning empty DataFrame.")
        return pd.DataFrame()
    
    print(f"\nSuccessfully processed {len(dfs)}/{len(files)} files")
    
    # Combine along columns (each sample is a column)
    combined_df = pd.concat(dfs, axis=1)
    
    # Fill missing values with zeros
    combined_df = combined_df.fillna(0)
    
    return combined_df

def load_metadata(metadata_file, sample_id_column='SampleID'):
    """
    Load and process metadata file.
    
    Parameters:
    -----------
    metadata_file : str
        Path to metadata file
    sample_id_column : str
        Column name for sample IDs
        
    Returns:
    --------
    pandas.DataFrame
        Metadata DataFrame with sample IDs as index
    """
    try:
        metadata_df = pd.read_csv(metadata_file)
        
        # Check if the sample ID column exists
        if sample_id_column not in metadata_df.columns:
            raise ValueError(f"Sample ID column '{sample_id_column}' not found in metadata")
            
        # Set index and remove any duplicate sample IDs
        metadata_df = metadata_df.set_index(sample_id_column)
        if metadata_df.index.duplicated().any():
            print(f"Warning: Found {metadata_df.index.duplicated().sum()} duplicate sample IDs in metadata")
            metadata_df = metadata_df[~metadata_df.index.duplicated(keep='first')]
        
        # Convert categorical variables to string
        for col in metadata_df.columns:
            if metadata_df[col].dtype == 'object' or metadata_df[col].dtype.name == 'category':
                metadata_df[col] = metadata_df[col].astype(str)
        
        return metadata_df
    
    except Exception as e:
        print(f"Error loading metadata file: {str(e)}")
        return pd.DataFrame()

def filter_low_abundance(abundance_df, min_prevalence=0.1, min_abundance=0.01):
    """
    Filter out low abundance and low prevalence taxa.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Taxa abundance DataFrame with taxa as index, samples as columns
    min_prevalence : float
        Minimum fraction of samples in which a taxon must be present
    min_abundance : float
        Minimum mean relative abundance a taxon must have
        
    Returns:
    --------
    pandas.DataFrame
        Filtered abundance DataFrame
    """
    # Calculate prevalence (fraction of samples where taxon is present)
    prevalence = (abundance_df > 0).mean(axis=1)
    
    # Calculate mean abundance
    mean_abundance = abundance_df.mean(axis=1)
    
    # Filter based on thresholds
    keep_taxa = (prevalence >= min_prevalence) & (mean_abundance >= min_abundance)
    
    print(f"Filtering from {len(abundance_df)} to {keep_taxa.sum()} taxa")
    print(f"  Prevalence threshold: {min_prevalence:.2f} (must be present in {min_prevalence*100:.1f}% of samples)")
    print(f"  Abundance threshold: {min_abundance:.4f} (must have mean abundance â‰¥ {min_abundance*100:.2f}%)")
    
    return abundance_df.loc[keep_taxa]

def differential_abundance_analysis(abundance_df, metadata_df, group_var, adjusted_p_threshold=0.05):
    """
    Identify differentially abundant taxa between groups.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Taxa abundance DataFrame with taxa as index, samples as columns
    metadata_df : pandas.DataFrame
        Metadata DataFrame with samples as index
    group_var : str
        Grouping variable in metadata (e.g., 'Severity', 'Symptoms')
    adjusted_p_threshold : float
        P-value threshold after multiple testing correction
        
    Returns:
    --------
    pandas.DataFrame
        Results of differential abundance testing
    """
    # Get common samples
    common_samples = list(set(abundance_df.columns).intersection(set(metadata_df.index)))
    
    if len(common_samples) < 5:
        print(f"Error: Not enough samples for differential abundance testing (found {len(common_samples)})")
        return pd.DataFrame()
    
    # Filter to common samples
    filtered_abundance = abundance_df[common_samples]
    
    # Get groups
    groups = metadata_df.loc[common_samples, group_var]
    unique_groups = groups.unique()
    
    if len(unique_groups) < 2:
        print(f"Error: Need at least 2 groups for differential abundance testing (found {len(unique_groups)})")
        return pd.DataFrame()
    
    # Determine which method to use based on number of groups
    if len(unique_groups) == 2:
        # Use Mann-Whitney U test for two groups
        results_df = _two_group_differential_testing(filtered_abundance, groups, unique_groups)
    else:
        # Use Kruskal-Wallis test for multiple groups
        results_df = _multi_group_differential_testing(filtered_abundance, groups, unique_groups)
    
    # Add variable name for reference
    results_df['Variable'] = group_var
    
    # Filter to significant results
    significant_df = results_df[results_df['Adjusted P-value'] < adjusted_p_threshold]
    
    print(f"Found {len(significant_df)} significantly different taxa (adj. p < {adjusted_p_threshold})")
    
    return results_df

def plot_timing_boxplot(abundance_df, metadata_df, taxon, time_var, output_file=None):
    """
    Create a boxplot showing taxon abundance changes across time points.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Taxa abundance DataFrame with taxa as index, samples as columns
    metadata_df : pandas.DataFrame
        Metadata DataFrame with samples as index
    taxon : str
        Taxon name to plot
    time_var : str
        Time variable column name (e.g., 'Timing')
    output_file : str, optional
        Path to save the plot
        
    Returns:
    --------
    matplotlib.figure.Figure
        Boxplot figure
    """
    # Get common samples
    common_samples = list(set(abundance_df.columns).intersection(set(metadata_df.index)))
    
    # Get taxon abundance
    if taxon not in abundance_df.index:
        print(f"Error: Taxon '{taxon}' not found in abundance data")
        return None
    
    taxon_abundance = abundance_df.loc[taxon, common_samples]
    
    # Get time information
    time_info = metadata_df.loc[common_samples, time_var].copy()
    
    # Create a DataFrame for plotting
    plot_data = pd.DataFrame({
        'Abundance': taxon_abundance,
        time_var: time_info
    })
    
    # Create figure
    fig, ax = plt.subplots(figsize=(10, 6))

    # Define the correct order for time points
    time_order = ['Prior', 'Acute', 'Post']
    
    # Ensure plot_data is initialized
    plot_data = metadata_df.copy()


    # Create a categorical variable with the correct order
    plot_data[time_var] = pd.Categorical(
        plot_data[time_var],
        categories=time_order,
        ordered=True
    )
    
    
    # Create boxplot
    sns.boxplot(x=time_var, y='Abundance', data=plot_data, ax=ax)
    
    # Add individual points
    sns.stripplot(x=time_var, y='Abundance', data=plot_data, 
                color='black', size=4, alpha=0.5, ax=ax)
    
    # Perform Kruskal-Wallis test
    try:
        groups = [plot_data[plot_data[time_var] == t]['Abundance'].values for t in plot_data[time_var].unique()]
        if all(len(g) > 0 for g in groups):
            stat, p_value = kruskal(*groups)
            ax.text(0.5, 0.01, f'Kruskal-Wallis p = {p_value:.3f}', ha='center', va='bottom', 
                  transform=ax.transAxes,
                  bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'))
    except:
        pass
    
    # Set title and labels
    ax.set_title(f'{taxon} Abundance Across Time Points')
    ax.set_xlabel(time_var)
    ax.set_ylabel('Abundance')
    
    # Adjust layout
    plt.tight_layout()
    
    # Save figure if output file is provided
    if output_file is not None:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Plot saved to {output_file}")
    
    return fig

def _two_group_differential_testing(abundance_df, groups, unique_groups):
    """Helper function for differential testing with two groups using Mann-Whitney U test."""
    # Initialize results
    results = []
    
    # Get sample indices for each group
    group1_samples = groups[groups == unique_groups[0]].index
    group2_samples = groups[groups == unique_groups[1]].index
    
    # Loop through each taxon
    for taxon in abundance_df.index:
        # Get abundance values for each group
        values1 = abundance_df.loc[taxon, group1_samples]
        values2 = abundance_df.loc[taxon, group2_samples]
        
        # Calculate mean abundance in each group
        mean1 = values1.mean()
        mean2 = values2.mean()
        
        # Calculate fold change (log2)
        # Add small pseudocount to avoid division by zero
        pseudocount = 1e-5
        fold_change = np.log2((mean2 + pseudocount) / (mean1 + pseudocount))
        
        # Perform Mann-Whitney U test
        try:
            stat, p_value = mannwhitneyu(values1, values2, alternative='two-sided')
        except Exception as e:
            # If test fails, set p-value to 1
            p_value = 1.0
            stat = np.nan
        
        results.append({
            'Taxon': taxon,
            'P-value': p_value,
            'Group1': unique_groups[0],
            'Group2': unique_groups[1],
            'Mean in Group1': mean1,
            'Mean in Group2': mean2,
            'Log2 Fold Change': fold_change,
            'Fold Change': 2**fold_change,
            'Test': 'Mann-Whitney U'
        })
    
    # Create DataFrame from results
    results_df = pd.DataFrame(results)
    
    # Apply multiple testing correction
    if not results_df.empty and len(results_df) > 1:
        try:
            # Use Benjamini-Hochberg procedure for FDR control
            results_df['Adjusted P-value'] = multipletests(
                results_df['P-value'], method='fdr_bh'
            )[1]
        except Exception as e:
            print(f"Error applying multiple testing correction: {str(e)}")
            results_df['Adjusted P-value'] = results_df['P-value']
    else:
        if not results_df.empty:
            results_df['Adjusted P-value'] = results_df['P-value']
    
    # Sort by adjusted p-value
    if not results_df.empty:
        results_df = results_df.sort_values('Adjusted P-value')
    
    return results_df

def _multi_group_differential_testing(abundance_df, groups, unique_groups):
    """Helper function for differential testing with multiple groups using Kruskal-Wallis test."""
    # Initialize results
    results = []
    
    # Loop through each taxon
    for taxon in abundance_df.index:
        # Initialize group values and means
        group_values = {}
        group_means = {}
        
        # Get values and calculate means for each group
        for group in unique_groups:
            group_samples = groups[groups == group].index
            group_values[group] = abundance_df.loc[taxon, group_samples]
            group_means[group] = group_values[group].mean()
        
        # Perform Kruskal-Wallis test
        try:
            # Prepare data for the test
            all_values = [group_values[group] for group in unique_groups]
            stat, p_value = kruskal(*all_values)
        except Exception as e:
            # If test fails, set p-value to 1
            p_value = 1.0
            stat = np.nan
        
        # Calculate maximum fold change between any two groups
        max_fold_change = 0
        max_group_pair = None
        
        for i, group1 in enumerate(unique_groups):
            for group2 in unique_groups[i+1:]:
                # Add small pseudocount to avoid division by zero
                pseudocount = 1e-5
                fold_change = np.abs(np.log2((group_means[group2] + pseudocount) / (group_means[group1] + pseudocount)))
                
                if fold_change > max_fold_change:
                    max_fold_change = fold_change
                    max_group_pair = (group1, group2)
        
        # Create result entry
        result = {
            'Taxon': taxon,
            'P-value': p_value,
            'Test': 'Kruskal-Wallis',
            'Max Log2 Fold Change': max_fold_change,
        }
        
        # Add mean for each group
        for group in unique_groups:
            result[f'Mean in {group}'] = group_means[group]
        
        # Add fold change information
        if max_group_pair:
            result['Max Fold Change Groups'] = f'{max_group_pair[0]} vs {max_group_pair[1]}'
            result['Fold Change'] = 2**max_fold_change
        
        results.append(result)
    
    # Create DataFrame from results
    results_df = pd.DataFrame(results)
    
    # Apply multiple testing correction
    if not results_df.empty and len(results_df) > 1:
        try:
            # Use Benjamini-Hochberg procedure for FDR control
            results_df['Adjusted P-value'] = multipletests(
                results_df['P-value'], method='fdr_bh'
            )[1]
        except Exception as e:
            print(f"Error applying multiple testing correction: {str(e)}")
            results_df['Adjusted P-value'] = results_df['P-value']
    else:
        if not results_df.empty:
            results_df['Adjusted P-value'] = results_df['P-value']
    
    # Sort by adjusted p-value
    if not results_df.empty:
        results_df = results_df.sort_values('Adjusted P-value')
    
    return results_df

def plot_taxa_boxplot(abundance_df, metadata_df, taxon, time_var, group_var, output_file=None):
    """
    Create a faceted boxplot showing taxon abundance across time points by group.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Taxa abundance DataFrame with taxa as index, samples as columns
    metadata_df : pandas.DataFrame
        Metadata DataFrame with samples as index
    taxon : str
        Taxon name to plot
    time_var : str
        Time variable column name (e.g., 'Timing')
    group_var : str
        Grouping variable column name (e.g., 'Severity', 'Symptoms')
    output_file : str, optional
        Path to save the plot
        
    Returns:
    --------
    matplotlib.figure.Figure
        Boxplot figure
    """
    # Get common samples
    common_samples = list(set(abundance_df.columns).intersection(set(metadata_df.index)))
    
    # Get taxon abundance
    if taxon not in abundance_df.index:
        print(f"Error: Taxon '{taxon}' not found in abundance data")
        return None
    
    taxon_abundance = abundance_df.loc[taxon, common_samples]
    
    # Get metadata information
    meta_subset = metadata_df.loc[common_samples, [time_var, group_var]].copy()

    # Define the correct order for time points
    time_order = ['Prior', 'Acute', 'Post']
    
    # Create a categorical variable with the correct order
    plot_data[time_var] = pd.Categorical(
        plot_data[time_var],
        categories=time_order,
        ordered=True
    )
    
    
    # Create a DataFrame for plotting
    plot_data = pd.DataFrame({
        'Abundance': taxon_abundance,
        time_var: meta_subset[time_var],
        group_var: meta_subset[group_var]
    })
    
    # Create figure with appropriate size for facets
    time_points = plot_data[time_var].unique()
    fig, axes = plt.subplots(1, len(time_points), figsize=(4*len(time_points), 5), sharey=True)
    
    # Handle the case with only one time point
    if len(time_points) == 1:
        axes = [axes]
    
    # Create boxplot for each time point
    for i, time_point in enumerate(sorted(time_points)):
        time_data = plot_data[plot_data[time_var] == time_point]
        
        # Create boxplot for this time point
        sns.boxplot(x=group_var, y='Abundance', data=time_data, ax=axes[i])
        
        # Add individual points
        sns.stripplot(x=group_var, y='Abundance', data=time_data, 
                     color='black', size=4, alpha=0.5, ax=axes[i])
        
        # Calculate p-value for this time point
        groups = time_data[group_var].unique()
        if len(groups) == 2:
            group1_data = time_data[time_data[group_var] == groups[0]]['Abundance']
            group2_data = time_data[time_data[group_var] == groups[1]]['Abundance']
            
            if len(group1_data) > 1 and len(group2_data) > 1:
                try:
                    _, p_value = mannwhitneyu(group1_data, group2_data, alternative='two-sided')
                    axes[i].text(0.5, 0.01, f'p = {p_value:.3f}', ha='center', va='bottom', 
                                transform=axes[i].transAxes,
                                bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.5'))
                except:
                    pass
        
        # Set title and labels
        axes[i].set_title(f'{time_point}')
        axes[i].set_xlabel(group_var)
        
        # Only add y-label to the first subplot
        if i == 0:
            axes[i].set_ylabel('Abundance')
        else:
            axes[i].set_ylabel('')
    
    # Add overall title
    plt.suptitle(f'{taxon} Abundance by {group_var} Across Time Points', fontsize=14, y=1.05)
    
    # Adjust layout
    plt.tight_layout()
    
    # Save figure if output file is provided
    if output_file is not None:
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"Plot saved to {output_file}")
    
    return fig

def analyze_by_timepoint(abundance_df, metadata_df, time_var, group_vars, adjusted_p_threshold=0.05):
    """
    Perform differential abundance analysis at each time point for each grouping variable.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Taxa abundance DataFrame with taxa as index, samples as columns
    metadata_df : pandas.DataFrame
        Metadata DataFrame with samples as index
    time_var : str
        Time variable column name (e.g., 'Timing')
    group_vars : list
        List of grouping variables to analyze (e.g., ['Severity', 'Symptoms'])
    adjusted_p_threshold : float
        P-value threshold after multiple testing correction
        
    Returns:
    --------
    dict
        Dictionary of differential abundance results by time point and group variable
    """
    # Check if time variable exists in metadata
    if time_var not in metadata_df.columns:
        print(f"Error: Time variable '{time_var}' not found in metadata")
        return {}
    
        # Define the correct order for time points
    time_order = ['Prior', 'Acute', 'Post']
    
    # Create a categorical variable with the correct order
    metadata_df[time_var] = pd.Categorical(
        metadata_df[time_var],
        categories=time_order,
        ordered=True
    )
    
    
    # Get all time points
    time_points = metadata_df[time_var].unique()
    
    # Initialize results dictionary
    results = {}
    
    # For each time point, analyze by each group variable
    for time_point in time_points:
        print(f"\nAnalyzing time point: {time_point}")
        
        # Get samples for this time point
        time_samples = metadata_df[metadata_df[time_var] == time_point].index
        
        # Get common samples with abundance data
        common_samples = list(set(time_samples).intersection(set(abundance_df.columns)))
        
        if len(common_samples) < 5:
            print(f"  Not enough samples for time point {time_point} (found {len(common_samples)}), skipping")
            continue
            
        # Filter abundance and metadata to this time point
        time_abundance = abundance_df[common_samples]
        time_metadata = metadata_df.loc[common_samples]
        
        # Initialize results for this time point
        results[time_point] = {}
        
        # Analyze by each group variable
        for group_var in group_vars:
            if group_var not in metadata_df.columns:
                print(f"  Warning: Group variable '{group_var}' not found in metadata, skipping")
                continue
                
            print(f"  Analyzing by {group_var}")
            
            # Perform differential abundance analysis
            diff_results = differential_abundance_analysis(
                time_abundance, 
                time_metadata, 
                group_var,
                adjusted_p_threshold
            )
            
            # Store results
            results[time_point][group_var] = diff_results
            
            # Print top significant results
            sig_results = diff_results[diff_results['Adjusted P-value'] < adjusted_p_threshold]
            
            if not sig_results.empty:
                print(f"    Top significant taxa:")
                for i, (_, row) in enumerate(sig_results.head(5).iterrows()):
                    if i < 5:  # Only show top 5
                        print(f"      {i+1}. {row['Taxon']}: adj. p-value = {row['Adjusted P-value']:.4f}")
    
    return results

def analyze_by_timing(abundance_df, metadata_df, time_var, adjusted_p_threshold=0.05):
    """
    Perform analysis to identify taxa that change significantly across time points.
    
    Parameters:
    -----------
    abundance_df : pandas.DataFrame
        Taxa abundance DataFrame with taxa as index, samples as columns
    metadata_df : pandas.DataFrame
        Metadata DataFrame with samples as index
    time_var : str
        Time variable column name (e.g., 'Timing')
    adjusted_p_threshold : float
        P-value threshold after multiple testing correction
        
    Returns:
    --------
    pandas.DataFrame
        Differential abundance results across time points
    """
    # Check if time variable exists in metadata
    if time_var not in metadata_df.columns:
        print(f"Error: Time variable '{time_var}' not found in metadata")
        return pd.DataFrame()
    
        # Define the correct order for time points
    time_order = ['Prior', 'Acute', 'Post']
    
    # Create a categorical variable with the correct order
    metadata_df[time_var] = pd.Categorical(
        metadata_df[time_var],
        categories=time_order,
        ordered=True
    )
    
    
    # Get all time points
    time_points = sorted(metadata_df[time_var].unique())
    
    if len(time_points) < 2:
        print(f"Error: Need at least 2 time points for temporal analysis")
        return pd.DataFrame()
    
    # Initialize results
    results = []
    
    # For each taxon, test for differences across time points
    for taxon in abundance_df.index:
        print(f"  Testing taxon: {taxon}")
        
        # Create DataFrame for analysis
        taxon_data = []
        
        for time_point in time_points:
            # Get samples for this time point
            time_samples = metadata_df[metadata_df[time_var] == time_point].index
            
            # Get common samples with abundance data
            common_samples = list(set(time_samples).intersection(set(abundance_df.columns)))
            
            if len(common_samples) < 3:
                print(f"    Not enough samples for time point {time_point} (found {len(common_samples)}), skipping taxon")
                continue
                
            # Get abundance values for this time point
            time_abundance = abundance_df.loc[taxon, common_samples]
            
            # Add to data
            for sample, abundance in time_abundance.items():
                taxon_data.append({
                    'Sample': sample,
                    'Abundance': abundance,
                    time_var: time_point
                })
        
        # Convert to DataFrame
        df = pd.DataFrame(taxon_data)
        
        # Skip if not enough data
        if len(df) < 5:
            continue
            
        # Perform Kruskal-Wallis test across time points
        try:
            # Group data by time point
            groups = [df[df[time_var] == time_point]['Abundance'].values for time_point in time_points
                     if len(df[df[time_var] == time_point]) > 0]
            
            # Skip if any group is empty
            if any(len(g) == 0 for g in groups):
                continue
                
            # Perform Kruskal-Wallis test
            stat, p_value = kruskal(*groups)
            
            # Calculate mean abundance for each time point
            time_means = {}
            for time_point in time_points:
                time_group = df[df[time_var] == time_point]
                if not time_group.empty:
                    time_means[time_point] = time_group['Abundance'].mean()
                else:
                    time_means[time_point] = np.nan
            
            # Calculate maximum fold change between any two time points
            max_fold_change = 0
            max_time_pair = None
            
            for i, time1 in enumerate(time_points):
                for time2 in time_points[i+1:]:
                    # Skip if either mean is NaN
                    if np.isnan(time_means[time1]) or np.isnan(time_means[time2]):
                        continue
                        
                    # Add small pseudocount to avoid division by zero
                    pseudocount = 1e-5
                    fold_change = np.abs(np.log2((time_means[time2] + pseudocount) / (time_means[time1] + pseudocount)))
                    
                    if fold_change > max_fold_change:
                        max_fold_change = fold_change
                        max_time_pair = (time1, time2)
            
            # Add results
            result = {
                'Taxon': taxon,
                'P-value': p_value,
                'Test': 'Kruskal-Wallis',
                'Max Log2 Fold Change': max_fold_change,
            }
            
            # Add mean for each time point
            for time_point in time_points:
                result[f'Mean at {time_point}'] = time_means.get(time_point, np.nan)
            
            # Add fold change information
            if max_time_pair:
                result['Max Fold Change Times'] = f'{max_time_pair[0]} vs {max_time_pair[1]}'
                result['Fold Change'] = 2**max_fold_change
            
            results.append(result)
            
        except Exception as e:
            print(f"    Error testing {taxon}: {str(e)}")
            continue
    
    # Create DataFrame from results
    results_df = pd.DataFrame(results)
    
    # Apply multiple testing correction
    if not results_df.empty and len(results_df) > 1:
        try:
            # Use Benjamini-Hochberg procedure for FDR control
            results_df['Adjusted P-value'] = multipletests(
                results_df['P-value'], method='fdr_bh'
            )[1]
        except Exception as e:
            print(f"Error applying multiple testing correction: {str(e)}")
            results_df['Adjusted P-value'] = results_df['P-value']
    else:
        if not results_df.empty:
            results_df['Adjusted P-value'] = results_df['P-value']
    
    # Sort by adjusted p-value
    if not results_df.empty:
        results_df = results_df.sort_values('Adjusted P-value')
        
        # Print top significant results
        sig_results = results_df[results_df['Adjusted P-value'] < adjusted_p_threshold]
        
        if not sig_results.empty:
            print(f"\nFound {len(sig_results)} taxa with significant changes across time points:")
            for i, (_, row) in enumerate(sig_results.head(10).iterrows()):
                if i < 10:  # Only show top 10
                    print(f"  {i+1}. {row['Taxon']}: adj. p-value = {row['Adjusted P-value']:.4f}")
    
    return results_df

def main():
    """Main function for RSV microbiome analysis."""
    # Parse arguments
    args = parse_args()
    
    # Set up output directories
    output_dir = Path(args.output_dir)
    abundance_dir = output_dir / "abundance_tables"
    results_dir = output_dir / "results"
    figures_dir = output_dir / "figures"
    boxplots_dir = figures_dir / "boxplots"
    
    # Create output directories
    for dir_path in [output_dir, abundance_dir, results_dir, figures_dir, boxplots_dir]:
        os.makedirs(dir_path, exist_ok=True)
    
    print(f"Output will be saved to {output_dir}")
    
    # Process Sylph files for bacteria, viruses, and fungi
    print("\n1. Processing Sylph output files")
    
    # Find bacterial profiles
    bacteria_pattern = os.path.join(args.input_dir, "*profiled_bacteria.tsv")
    bacteria_files = glob.glob(bacteria_pattern)
    
    if bacteria_files:
        print(f"\nProcessing {len(bacteria_files)} bacterial profile files...")
        bacteria_df = combine_sylph_samples(
            bacteria_files, 
            abundance_type=args.abundance_type,
            min_ani=args.min_ani,
            min_coverage=args.min_coverage
        )
        
        if not bacteria_df.empty:
            # Save combined table
            bacteria_file = abundance_dir / 'bacteria_abundance.csv'
            bacteria_df.to_csv(bacteria_file)
            print(f"Bacterial abundance table saved to {bacteria_file}")
            print(f"Table contains {len(bacteria_df.index)} taxa across {len(bacteria_df.columns)} samples")
    else:
        print("No bacterial profile files found")
        bacteria_df = pd.DataFrame()
    
    # Find viral profiles
    virus_pattern = os.path.join(args.input_dir, "*profiled_viruses.tsv")
    virus_files = glob.glob(virus_pattern)
    
    if virus_files:
        print(f"\nProcessing {len(virus_files)} viral profile files...")
        virus_df = combine_sylph_samples(
            virus_files, 
            abundance_type=args.abundance_type,
            min_ani=args.min_ani,
            min_coverage=args.min_coverage
        )
        
        if not virus_df.empty:
            # Save combined table
            virus_file = abundance_dir / 'virus_abundance.csv'
            virus_df.to_csv(virus_file)
            print(f"Viral abundance table saved to {virus_file}")
            print(f"Table contains {len(virus_df.index)} taxa across {len(virus_df.columns)} samples")
    else:
        print("No viral profile files found")
        virus_df = pd.DataFrame()
    
    # Find fungal profiles
    fungi_pattern = os.path.join(args.input_dir, "*profiled_fungi.tsv")
    fungi_files = glob.glob(fungi_pattern)
    
    if fungi_files:
        print(f"\nProcessing {len(fungi_files)} fungal profile files...")
        fungi_df = combine_sylph_samples(
            fungi_files, 
            abundance_type=args.abundance_type,
            min_ani=args.min_ani,
            min_coverage=args.min_coverage
        )
        
        if not fungi_df.empty:
            # Save combined table
            fungi_file = abundance_dir / 'fungi_abundance.csv'
            fungi_df.to_csv(fungi_file)
            print(f"Fungal abundance table saved to {fungi_file}")
            print(f"Table contains {len(fungi_df.index)} taxa across {len(fungi_df.columns)} samples")
    else:
        print("No fungal profile files found")
        fungi_df = pd.DataFrame()
    
    # Create a combined table with all microbes
    print("\nCreating combined microbial abundance table...")
    combined_tables = []
    
    if not bacteria_df.empty:
        bacteria_df.index = ['Bacteria: ' + idx for idx in bacteria_df.index]
        combined_tables.append(bacteria_df)
        
    if not virus_df.empty:
        virus_df.index = ['Virus: ' + idx for idx in virus_df.index]
        combined_tables.append(virus_df)
        
    if not fungi_df.empty:
        fungi_df.index = ['Fungus: ' + idx for idx in fungi_df.index]
        combined_tables.append(fungi_df)
    
    if combined_tables:
        all_microbes_df = pd.concat(combined_tables)
        all_microbes_file = abundance_dir / 'all_microbes_abundance.csv'
        all_microbes_df.to_csv(all_microbes_file)
        print(f"Combined microbial abundance table saved to {all_microbes_file}")
        print(f"Table contains {len(all_microbes_df.index)} taxa across {len(all_microbes_df.columns)} samples")
    else:
        print("No data to combine into a microbial abundance table.")
        return
    
    # Load metadata
    print("\n2. Loading metadata")
    if os.path.exists(args.metadata):
        metadata_df = load_metadata(args.metadata, args.sample_id_column)
        
        if metadata_df.empty:
            print("Error: Could not load metadata")
            return
            
        print(f"Loaded metadata for {len(metadata_df)} samples")
        
        # Check sample overlap
        common_samples = set(all_microbes_df.columns).intersection(set(metadata_df.index))
        print(f"Found {len(common_samples)} samples in both abundance data and metadata")
        
        if len(common_samples) < 5:
            print("Error: Not enough common samples for analysis")
            return
            
    else:
        print(f"Error: Metadata file not found at {args.metadata}")
        return
    
    # Filter to keep only common samples
    all_microbes_df = all_microbes_df[list(common_samples)]
    
    # Filter low-abundance and low-prevalence taxa
    print("\n3. Filtering low-abundance and low-prevalence taxa")
    filtered_df = filter_low_abundance(
        all_microbes_df, 
        min_prevalence=args.min_prevalence,
        min_abundance=args.min_abundance
    )
    
    # Save filtered abundance table
    filtered_file = abundance_dir / 'filtered_abundance.csv'
    filtered_df.to_csv(filtered_file)
    print(f"Filtered abundance table saved to {filtered_file}")
    
    # Analyze by timing (Prior, Acute, Post)
    print("\n4. Analyzing changes across timing (Prior, Acute, Post)")
    timing_var = 'Timing'  # Adjust if your metadata uses a different column name
    
    if timing_var not in metadata_df.columns:
        print(f"Error: Timing variable '{timing_var}' not found in metadata")
        return
        
    timing_results = analyze_by_timing(filtered_df, metadata_df, timing_var)
    
    if not timing_results.empty:
        # Save timing results
        timing_file = results_dir / 'timing_differential_abundance.csv'
        timing_results.to_csv(timing_file)
        print(f"Timing analysis results saved to {timing_file}")
        
        # Create plots for top taxa
        significant_taxa = timing_results[timing_results['Adjusted P-value'] < 0.05]['Taxon'].tolist()
        
        if significant_taxa:
            print(f"\nCreating boxplots for {len(significant_taxa)} taxa with significant timing changes")
            
            for i, taxon in enumerate(significant_taxa[:10]):  # Plot top 10
                try:
                    output_file = boxplots_dir / f"timing_{taxon.replace(' ', '_').replace(':', '_')}.pdf"
                    plot_timing_boxplot(filtered_df, metadata_df, taxon, timing_var, output_file)
                except Exception as e:
                    print(f"Error creating plot for {taxon}: {str(e)}")
    
    # Analyze by severity and symptoms at each time point
    print("\n5. Analyzing differences by severity and symptoms at each time point")
    group_vars = ['Severity', 'Symptoms']  # Adjust if your metadata uses different column names
    
    # Check if group variables exist in metadata
    missing_vars = [var for var in group_vars if var not in metadata_df.columns]
    if missing_vars:
        print(f"Warning: The following group variables are missing from metadata: {missing_vars}")
        group_vars = [var for var in group_vars if var not in missing_vars]
        
    if not group_vars:
        print("Error: No valid group variables for analysis")
        return
    
    # Perform analysis by time point for each group variable
    time_point_results = analyze_by_timepoint(filtered_df, metadata_df, timing_var, group_vars)
    
    # Save results for each time point and group variable
    for time_point, group_results in time_point_results.items():
        for group_var, results_df in group_results.items():
            if not results_df.empty:
                # Save results
                result_file = results_dir / f"{time_point}_{group_var}_differential_abundance.csv"
                results_df.to_csv(result_file)
                print(f"Results for {time_point} by {group_var} saved to {result_file}")
                
                # Create plots for significant taxa
                significant_taxa = results_df[results_df['Adjusted P-value'] < 0.05]['Taxon'].tolist()
                
                if significant_taxa:
                    print(f"\nCreating boxplots for {len(significant_taxa)} taxa with significant {group_var} differences at {time_point}")
                    
                    for i, taxon in enumerate(significant_taxa[:10]):  # Plot top 10
                        try:
                            output_file = boxplots_dir / f"{time_point}_{group_var}_{taxon.replace(' ', '_').replace(':', '_')}.pdf"
                            plot_taxa_boxplot(filtered_df, metadata_df, taxon, timing_var, group_var, output_file)
                        except Exception as e:
                            print(f"Error creating plot for {taxon}: {str(e)}")
    
    print("\nAnalysis complete!")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"Error in main execution: {str(e)}")
        traceback.print_exc()

